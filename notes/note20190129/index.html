<!DOCTYPE HTML>
<html>
    <!-- Header -->
    <head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<meta name="description" content="A Ph.D student in University of Houston (UH). Interested area includes: machine learning, programming and religion.">
	<meta name="author" content="Yuchen Jin">
	
	<meta name="generator" content="Hugo 0.55.1" />
	<title>Notes from Jan. 29, 2019 to Feb. 15, 2019 &middot; Rosenkreutz Studio</title>
	<!-- Stylesheets -->
	
	<link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.3.1/semantic.min.css" rel="stylesheet" type="text/css">
	<link rel="stylesheet" type="text/css" href="https://cainmagi.github.io/css/tooltipster.bundle.min.css" />
	<link rel="stylesheet" type="text/css" href="https://cainmagi.github.io/css/tooltipster-sideTip-borderless.min.css" />
	<link rel="stylesheet" href="https://cainmagi.github.io/css/main.css"/>
	<link rel="stylesheet" href="https://cainmagi.github.io/css/title.css"/>
	<link rel="stylesheet" href="https://cainmagi.github.io/css/extensions.css"/>
	<link rel="stylesheet" href="https://cainmagi.github.io/css/jq-images.css"/>
	
	

	

	<!-- Custom Fonts -->
	
	
	<link href="https://cainmagi.github.io/css/font-awesome.min.css" rel="stylesheet" type="text/css">
	<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

	
	<link rel="shortcut icon" type="image/x-icon" href="https://cainmagi.github.io/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://cainmagi.github.io/favicon.ico">
	

	<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
	<!--[if lt IE 9]>
	<script src="js/ie/html5shiv.js"></script>
	<script src="js/ie/html5shiv.jsrespond.min.js"></script>
	<![endif]-->
</head>

    <body>

    <!-- Wrapper -->
    <div id="wrapper">

            <!-- Header -->
    <header id="header" class="alt">
        <a href="https://cainmagi.github.io/" class="logo"><strong>CainMagi</strong> <span>University of Houston</span></a>
        <nav>
            <a href="#menu">Menu</a>
        </nav>
    </header>

<!-- Menu -->
    <nav id="menu">
        <ul class="links">
            
                <li><a href="https://cainmagi.github.io/">Home</a></li>
            
                <li><a href="https://cainmagi.github.io/about">About</a></li>
            
                <li><a href="https://cainmagi.github.io/notes">Notes</a></li>
            
                <li><a href="https://cainmagi.github.io/researches">Researches</a></li>
            
                <li><a href="https://cainmagi.github.io/projects">Projects</a></li>
            
                <li><a href="https://cainmagi.github.io/playground">Playground</a></li>
            

        </ul>
        <ul class="actions vertical">
            
                <li><a href="http://welllogging.egr.uh.edu/" class="button special fit">Laboratory Page</a></li>
            
            
        </ul>
    </nav>

        <!-- Main -->
            <div id="main" class="alt">

                
                    <section id="one">
                        <div class="inner">
                            <header id="pagetitle" class="major">
                                <h1 id='main_title'>Notes from Jan. 29, 2019 to Feb. 15, 2019</h1>
                                <table class="sub-title">
                                    <tbody>
                                        <tr>
                                            <th>Date:</th>
                                            <td>Jan 29, 2019</td>
                                        </tr> 
                                        <tr>
                                            <th>Last Updated:</th>
                                            <td>Feb 15, 2019</td>
                                        </tr>
                                        <tr>
                                            <th>Categories:</th>
                                            <td><section class="dream-tags">
                                                    <a class="ui label categ" href="/categories/notes" title="Notes">Notes</a>
                                                    
                                                    <a class="ui label categ" href="/categories/papers" title="Papers">Papers</a>
                                                    
                                                
                                            </section></td>
                                        </tr>
                                        <tr>
                                            <th>Tags:</th>
                                            <td><section class="dream-tags">
                                                    <a class="ui label" href="/tags/research" title="research">research</a>
                                                    
                                                    <a class="ui label" href="/tags/deep-learning" title="deep-learning">deep-learning</a>
                                                    
                                                    <a class="ui label" href="/tags/stochastic" title="stochastic">stochastic</a>
                                                    
                                                    <a class="ui label" href="/tags/inverse-problem" title="inverse-problem">inverse-problem</a>
                                                    
                                                    <a class="ui label" href="/tags/nips" title="NIPS">NIPS</a>
                                                    
                                                
                                            </section></td>
                                        </tr>
                                    </tbody>
                                </table>
                                
                                <span class="image main"><img src="/img/notes/default.jpg" alt="" /></span>
                                
                            </header>
                            
                            <hr/>
                            <h1 id="contents">Contents</h1>
                            <p><nav id="TableOfContents">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#optimizing-methods">Optimizing methods</a>
<ul>
<li><a href="#optimizing-methods-for-solving-non-linear-inverse-problem">Optimizing methods for solving non-linear inverse problem</a>
<ul>
<li><a href="#conjugate-gradient-descent">Conjugate gradient descent</a></li>
<li><a href="#frank-wolfe-algorithm">Frank–Wolfe Algorithm</a></li>
</ul></li>
<li><a href="#optimizing-methods-for-solving-linear-inverse-problem">Optimizing methods for solving linear inverse problem</a>
<ul>
<li><a href="#lista-cpss-algorithm">LISTA-CPSS Algorithm</a></li>
<li><a href="#inf-admm-adnn">Inf-ADMM-ADNN</a></li>
<li><a href="#vamp-equipped-with-non-separable-denoiser">VAMP equipped with non-separable denoiser</a></li>
</ul></li>
<li><a href="#regularization-penalty">Regularization / Penalty</a>
<ul>
<li><a href="#adversarial-regularizers">Adversarial Regularizers</a></li>
<li><a href="#proximal-gradient-method">Proximal gradient method</a></li>
<li><a href="#landweber-iteration">Landweber iteration</a></li>
</ul></li>
</ul></li>
<li><a href="#stochastic-methods">Stochastic methods</a>
<ul>
<li><a href="#sampling-methods">Sampling methods</a>
<ul>
<li><a href="#metropolis-hastings">Metropolis-Hastings</a></li>
<li><a href="#gibbs-sampling">Gibbs sampling</a></li>
</ul></li>
<li><a href="#heuristic-methods">Heuristic methods</a>
<ul>
<li><a href="#ant-colony-algorithm">Ant colony algorithm</a></li>
<li><a href="#bat-algorithm">Bat algorithm</a></li>
</ul></li>
</ul></li>
<li><a href="#related-slides">Related slides</a>
<ul>
<li><a href="#slides-on-week-1-feb-1-2019">Slides on week 1, Feb. 1, 2019</a></li>
<li><a href="#slides-on-week-2-feb-8-2019">Slides on week 2, Feb. 8, 2019</a></li>
<li><a href="#slides-on-week-3-a-feb-13-2019">Slides on week 3-a, Feb. 13, 2019</a></li>
<li><a href="#slides-on-week-3-b-feb-15-2019">Slides on week 3-b, Feb. 15, 2019</a></li>
</ul></li>
</ul>
</nav></p>
                            
                            <hr/>
                            

<h1 id="introduction">Introduction</h1>

<p>In this article we would summarize some popular solutions for the inverse problem. To be specific, here we only discuss the methods of inverse problems. Although when introducing some algorithms, we may need to explain what problem they work on, the various topics about which problem we solve is not what we concentrate on in this article.</p>

<p>Generally the solutions could be divided into 2 parts: optimizing methods and stochastic approaches. In the first part, i.e. the optimizing methods, we would introduce different iterative algorithms which are used to find the optimal solution of the problem. In most cases, these algorithms are based on deterministic methods, i.e. the derivatives. In the second part, we would introduce some stochastic methods especially some heuristic methods where we do not need to calculate the gradient but only need to evaluate the loss function. In those 2 parts, we would also talks about machine learning, regularization and some other related topics which have been applied to enhance the performance of the plain algorithms.</p>

<p>In the following parts, we will show not only the methods and ideas but also the state-of-art progress on inverse problem. Our literature resource is mainly from <a href="https://papers.nips.cc">NIPS</a> and <a href="https://ieeexplore.ieee.org/Xplore/home.jsp">IEEE Xplore</a>.</p>

<p>In the last section, we attach 3 groups of slides which are related to this article. The slides include the weekly report from 02/01/2019 to 02/15/2019.</p>

<h1 id="optimizing-methods">Optimizing methods</h1>

<h2 id="optimizing-methods-for-solving-non-linear-inverse-problem">Optimizing methods for solving non-linear inverse problem</h2>

<h3 id="conjugate-gradient-descent">Conjugate gradient descent</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: A new family of conjugate gradient methods for unconstrained optimization</li>
        <li><b>Author</b>: Mohd Rivaie, Muhammad Fauzi, and Mustafa Mamat</li>
        <li><b>Year</b>: 2011</li>
        <li><b>Theory level</b>: Theoretical</li>
        <li><b>Theory type</b>: Gradient based algotirhm</li>
        <li><b>Used data</b>: Standard testing benchmarks</li>
        <li><b>Source</b>: International Conference on Modeling, Simulation and Applied Optimization</li>
        </ul>
        <p style="text-indent:2em"><a href="https://ieeexplore.ieee.org/document/5775548" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
        <ul>
        <li><b>External Reference</b>: <i>A modified PRP conjugate gradient method with Armijo line search for large-scale unconstrained optimization</i>.</li>
        </ul>
        <p style="text-indent:2em"><a href="https://ieeexplore.ieee.org/document/8027748" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>This paper proposes a new conjugate gradient coefficient which is used in conjugate gradient descent method. As an alternative of Newton's method, conjugate gradient method aims at approximating the Hessian matrix with first order gradient to avoid the computationally expensive second-order term. Regardless the computational cost, this method is slower than Newton's method but faster than first-order gradient descent.</p>
        <p>Denote that we need to solve such an unconstrained problem which could be non-linear,</p>
        <div class="overflow">
        \begin{align}
            \hat{\mathbf{x}} = \arg \min\limits_{\mathbf{x}} f(\mathbf{x}).
        \end{align}
        </div>
        <p>The algorithm could be described as:</p>
        <ol>
            <li>Initialize the input parameter $\mathbf{x}_0$, $k=0$.</li>
            <li>Calculate first-order gradient $\mathbf{g}_k = \nabla f(\mathbf{x}_k)$.</li>
            <li>Compute $\boldsymbol{\beta}_k$ which is the conjugate gradient coefficient.</li>
            <li>Update descent direction: when $k=0$, let $\mathbf{d}_k=-\mathbf{g}_k$; when $k &gt; 0$, $\mathbf{d}_k=-\mathbf{g}_k+\boldsymbol{\beta}_k\mathbf{d}_{k-1}$.</li>
            <li>Use line search to find the best update parameter: $\alpha_k=\arg \min_{\alpha}f(\mathbf{x}_k+\alpha \mathbf{d}_k)$.</li>
            <li>Let $\mathbf{x}_{k+1} = \mathbf{x}_k+\alpha_k \mathbf{d}_k$. If $f(\mathbf{x}_{k+1}) &lt; f(\mathbf{x}_k)$ and $\lVert \mathbf{g}_k \rVert &lt; \varepsilon$, stop; otherwise get back to step 2.</li>
        </ol>
        <p>The author also proposes a new conjugate gradient coefficient and proves the convergence of the new coefficient.</p>
    </div>
  </div>
</div>

<h3 id="frank-wolfe-algorithm">Frank–Wolfe Algorithm</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Decentralized Frank–Wolfe Algorithm for Convex and Nonconvex Problems</li>
        <li><b>Author</b>: Hoi-To Wai, Jean Lafond, Anna Scaglione, and Eric Moulines</li>
        <li><b>Year</b>: 2017</li>
        <li><b>Theory level</b>: Theoretical</li>
        <li><b>Theory type</b>: Gradient based algotirhm</li>
        <li><b>Used data</b>: Standard testing benchmarks</li>
        <li><b>Source</b>: IEEE Transactions on Automatic Control</li>
        </ul>
        <p style="text-indent:2em"><a href="https://ieeexplore.ieee.org/document/7883821" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>This paper introduce a decentralized version of Frank–Wolfe Algorithm which is used to solve a strictly constrained optimizing problem. In this paper, the author assume that there a series of functions $f_i (\mathbf{x})$ which might not be convex, then the problem is</p>
        <div class="overflow">
        \begin{align}
            \hat{\mathbf{x}} = \arg \min\limits_{\mathbf{x} \in \mathcal{D}} F(\mathbf{x}) = \arg \min\limits_{\mathbf{x} \in \mathcal{D}} \sum_i f_i(\mathbf{x}).
        \end{align}
        </div>
        <p>Denote that the adjacent matrix $\mathbf{W}$ has such condition: $\sum_{j} W_{ij} = 1$. Then the algorithm could be described as:</p>
        <ol>
            <li>For each agent, calculate the local average iterate among its neighbor: $\bar{\mathbf{x}}_i = \sum_{j} W_{ij} \mathbf{x}_j$, where $W_{ij}$ is an element of the adjacent matrix.</li>
            <li>For each agent, calculate the local average gradient among its neighbor: $\overline{\nabla F}_i= \sum_{j} W_{ij} \nabla f_j (\mathbf{x}_j)$.</li>
            <li>Let $\boldsymbol{\alpha}_i =  \arg \min\limits_{\boldsymbol{\alpha}_i \in \mathcal{D}} \boldsymbol{\alpha}_i^T \overline{\nabla F}_i$.</li>
            <li>Update iterate: $\mathbf{x}_{i+1} = (1-\gamma) \bar{\mathbf{x}}_i + \gamma \boldsymbol{\alpha}_i$.</li>
        </ol>
        <p>Note that the domain $\mathcal{D}$ is a strict constraint. For example, we could set that $\mathcal{D} = \{ \mathbf{x} | \lVert \mathbf{x} \rVert_1 &lt; \lambda \}$. Then the problem would become a lasso problem.</p>
        <p>The author also discuss the convergence when $f_i$ is convex functions, and the bound when $f_i$ is non-convex. Compared to the conventional FW algorithm, the proposed one is decentralized, which means it could make use of multiple agents and the parallel computing. The author has proved that although in the algorithm we only calculate the "local average" for each agent, when considering the whole system product, the "local average" would converge to the real one.</p>
        <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Frank-Wolfe_Algorithm.png/440px-Frank-Wolfe_Algorithm.png"/></p>
    </div>
  </div>
</div>

<h2 id="optimizing-methods-for-solving-linear-inverse-problem">Optimizing methods for solving linear inverse problem</h2>

<h3 id="lista-cpss-algorithm">LISTA-CPSS Algorithm</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Theoretical Linear Convergence of Unfolded ISTA and its PracticalWeights and Thresholds</li>
        <li><b>Author</b>: Xiaohan Chen, Jialin Liu, Zhangyang Wang and Wotao Yin</li>
        <li><b>Year</b>: 2018</li>
        <li><b>Theory level</b>: Theoretical</li>
        <li><b>Theory type</b>: Machine learning</li>
        <li><b>Used data</b>: 11 test images for sparse coding</li>
        <li><b>Source</b>: Advances in Neural Information Processing Systems 31 (NIPS 2018) pre-proceedings</li>
        </ul>
        <p style="text-indent:2em"><a href="https://papers.nips.cc/paper/8120-theoretical-linear-convergence-of-unfolded-ista-and-its-practical-weights-and-thresholds" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>This paper concentrates on the inspection on LISTA (Learning-ISTA). To check the basic idea of LISTA and LAMP, please check this article:</p>
        <p style="text-indent:2em"><a href="../note20180813special/#proposed-methods" class="button icon fa-file-text-o" style="text-indent:0em">Reference</a></p>
        <p>LISTA which is adapted from ISTA, has 2 weight matrices in each layer. The network structure could be described in the following figure.</p>
        <p><img src="./lista.svg"/></p>
        <p>The network still preserves the workflow of ISTA. The observed data is the input for each layer, while we still need an initial guess for the prediction. The initial guess is passed to the first layer and adjusted in each layer until we get the accurate prediction.</p>
        <p>In this paper, the author propose two improvements on the original LISTA:</p>
        <ol>
            <li><b>Partial weight coupling (CP)</b>: The author proves that the primal LISTA could not converge unless $\mathbf{W}_{k2} = \mathbf{I} - \mathbf{W}_{k1} \mathbf{A}$. Hence we would only has one weight matrix in each layer.</li>
            <li><b>Support selection technique</b>: The author proposes that after we calculate the $\mathbf{v}_k = \mathbf{W}_{k1} \mathbf{b} + \mathbf{W}_{k2} \mathbf{x}_k$, we could use a new threshold technique. When $\mathbf{v}_k$ is small, use soft thresholding; when $\mathbf{v}_k$ is large, use hard thresholding.</li>
        </ol>
        <p>With the two above methods equipped, the convergence speed would be accelerated.</p>
    </div>
  </div>
</div>

<h3 id="inf-admm-adnn">Inf-ADMM-ADNN</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: An inner-loop free solution to inverse problems using deep neural networks</li>
        <li><b>Author</b>: Kai Fan, Qi Wei, Lawrence Carin and Katherine A. Heller</li>
        <li><b>Year</b>: 2017</li>
        <li><b>Theory level</b>: Application</li>
        <li><b>Theory type</b>: Machine learning</li>
        <li><b>Used data</b>: Deblurring, super resolution and colorization</li>
        <li><b>Source</b>: Advances in Neural Information Processing Systems 30 (NIPS 2017)</li>
        </ul>
        <p style="text-indent:2em"><a href="https://papers.nips.cc/paper/6831-an-inner-loop-free-solution-to-inverse-problems-using-deep-neural-networks" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
        <ul>
          <li><b>External Reference</b>: <i>Distributed optimization and statistical learning via the alternating direction method of multipliers</i>.</li>
        </ul>
        <p style="text-indent:2em"><a href="https://stanford.edu/class/ee367/reading/admm_distr_stats.pdf" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>This paper aims at solve a general form of liner inverse problem:</p>
        <div class="overflow">
        \begin{equation}
          \begin{aligned}
            \arg \min\limits_{\mathbf{x}} &\lVert \mathbf{y} - \mathbf{A}\mathbf{z} \rVert + \lambda \mathcal{R}(\mathbf{x},~\mathbf{y}),\\
            \mathrm{s.t.}&~\mathbf{z}=\mathbf{x}.
          \end{aligned}
        \end{equation}
        </div>
        <p>By using Lagrange multiplier method, we could decompose this optimization into 3 steps in each iteration. We call this method alternating direction method of multipliers (ADMM) framework:</p>
        <div class="overflow">
        \begin{equation}
          \left\{
          \begin{aligned}
            \mathbf{x}^{k+1} &= \arg \min\limits_{\mathbf{x}} \beta \left\lVert \mathbf{x} - \mathbf{z}^k + \frac{\mathbf{u}^k}{2\beta} \right\rVert^2 + \lambda \mathcal{R}(\mathbf{x},~\mathbf{y}), \\
            \mathbf{z}^{k+1} &= \arg \min\limits_{\mathbf{z}} \left\lVert \mathbf{y} - \mathbf{A}\mathbf{z} \right\rVert^2 + \beta \left\lVert \mathbf{x} - \mathbf{z}^k + \frac{\mathbf{u}^k}{2\beta} \right\rVert^2, \\
            \mathbf{u}^{k+1} &= \mathbf{u}^k + 2 \beta \left( \mathbf{x}^{k+1} - \mathbf{z}^{k+1} \right)
          \end{aligned}
          \right.
        \end{equation}
        </div>
        <p>In practice, the matrix $\mathbf{A}$ may be a very large one. To solve this problem, we have overcome two main challenges. The first one is the solution for $\mathbf{z}^{k+1}$. Although it has a closed-form solution, we need to calculate the inverse of $\mathbf{B} = \left( \beta\mathbf{I} + \mathbf{A}\mathbf{A}^T \right)^{-1}$. Thus the author proposes a network which is used to learn $\mathbf{C}_{\phi} \rightarrow \mathbf{B}^{-1}$</p>
        <p><img src="./adnn-net1.svg"/></p>
        <p>In some cases, for example, if $\mathcal{R} = \lVert \cdot \rVert_1$, $\mathbf{x}^{k+1}$ which is deduced from proximal operator could get the closed-form solution. However, if $\mathcal{R}$ is in a generalized form, for the proximal operator $\arg\min\limits_{\mathbf{x}} \frac{1}{2} \lVert \mathbf{x} - \mathbf{v} \rVert_2^2 + \mathcal{R}(\mathbf{x},~\mathbf{y})$, we could find that</p>
        <div class="overflow">
        \begin{align}
            \mathbf{v} - \mathbf{x} \propto \partial \mathcal{R}.
        \end{align}
        </div>
        <p>Thus we know that $\mathbf{v} = \mathcal{F} (\mathbf{x})$. And we use the following network to learn the inverse $\mathbf{x} = \mathcal{F}^{-1}(\mathbf{v})$.</p>
        <p><img src="./adnn-net2.svg"/></p>
    </div>
  </div>
</div>

<h3 id="vamp-equipped-with-non-separable-denoiser">VAMP equipped with non-separable denoiser</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis</li>
        <li><b>Author</b>: Alyson K. Fletcher, Parthe Pandit, Sundeep Rangan, Subrata Sarkar and Philip Schniter</li>
        <li><b>Year</b>: 2018</li>
        <li><b>Theory level</b>: Theoretical</li>
        <li><b>Theory type</b>: Gradient based algorithm</li>
        <li><b>Used data</b>: Compressive Image Recovery and Lifting</li>
        <li><b>Source</b>: Advances in Neural Information Processing Systems 31 (NIPS 2018) pre-proceedings</li>
        </ul>
        <p style="text-indent:2em"><a href="https://papers.nips.cc/paper/7973-plug-in-estimation-in-high-dimensional-linear-inverse-problems-a-rigorous-analysis" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
        <ul>
          <li><b>External Reference</b>: To learn more about AMP, please check this note:</li>
        </ul>
        <p style="text-indent:2em"><a href="../note20180813special/#proposed-methods" class="button icon fa-file-text-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>This paper extends the Vector-AMP (VAMP) to a wider case. First, let us introduce VAMP. VAMP extend the conventional AMP into a two-part iteration structure. In the first part, we use a denoising operator $\mathbf{g}_1(\cdot)$ as we have done in AMP. In the other part, we use a linear minimum mean-squared error (LMMSE) operator to ensure a state evolution (SE) analysis. This technique extend the algorithm to a case that $\mathbf{A}$ is not required to be in the i.i.d. sub-Gaussian distribution but only need to be an arbitrary right rotationally invariant matrix.</p>
        <p>This is the algorithm of VAMP:</p>
        <p><img src="./vampns-alg.svg"/></p>
        <p>The sub-structure in each part is the same as AMP. However, in this algorithm, we have 2 function vectors $\mathbf{g}_1(\cdot)$ and $\mathbf{g}_2(\cdot)$, where $\mathbf{g}_2(\cdot)$ needs to be a solution to the L2-penalized linear inverse problem:</p>
        <div class="overflow">
        \begin{align}
            \mathbf{g}_2(\mathbf{r}_{2k},~ \gamma_{2k}) := \left( \gamma_{\omega} \mathbf{A}^T\mathbf{A} + \gamma_{2k}\mathbf{I} \right)^{-1} \left( \gamma_{2k} \mathbf{A}^T\mathbf{y} + \gamma_{2k}\mathbf{r}_{2k} \right).
        \end{align}
        </div>
        <p>However, $\mathbf{g}_1(\cdot)$ could be many kinds of denoisers. For example, soft thresholding is the solution derived from L<sub>1</sub> norm penalty, which is a separable denoiser. In this article, the author propose that with the ground truth $\mathbf{x}^{\ast}$ companied by Gaussian noise, both of the errors $\mathbf{p}_k = \mathbf{r}_{1k} - \mathbf{x}^{\ast}$ and $\mathbf{q}_k = \mathbf{V}^T \left(\mathbf{r}_{1k} - \mathbf{x}^{\ast}\right)$</p> converge to a vector with each element in the Gaussian distribution with zero mean and $\tau_{1k}$, $\tau_{2k}$ variance respectively.
    </div>
  </div>
</div>

<h2 id="regularization-penalty">Regularization / Penalty</h2>

<h3 id="adversarial-regularizers">Adversarial Regularizers</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Adversarial Regularizers in Inverse Problems</li>
        <li><b>Author</b>: Sebastian Lunz, Carola Schoenlieb and Ozan Öktem</li>
        <li><b>Year</b>: 2018</li>
        <li><b>Theory level</b>: Theoretical</li>
        <li><b>Theory type</b>: Machine learning</li>
        <li><b>Used data</b>: image inverse, the data is from BSDS500 dataset</li>
        <li><b>Source</b>: Advances in Neural Information Processing Systems 31 (NIPS 2018) pre-proceedings</li>
        </ul>
        <p style="text-indent:2em"><a href="https://papers.nips.cc/paper/8070-adversarial-regularizers-in-inverse-problems" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>Consider such a problem:</p>
        <div class="overflow">
        \begin{align}
            \hat{\mathbf{x}} = \arg \min\limits_{\mathbf{x}} \lVert \mathbf{y} - \mathbf{A}\mathbf{x}\rVert_2^2 + \lambda f(\mathbf{x}).
        \end{align}
        </div>
        <p>This paper proposes that we could use a network $\Psi_{\boldsymbol{\Theta}}(\cdot)$ to replace the regularization term $f$. Since the network could learn from the distribution of the data, it could serve better than a specially designed regularization.</p>
        <p>Considering that $\mathbf{y} = \mathbf{A} \mathbf{x}$, we may have a direct inverse method that $\mathbf{x} = \mathbf{A}^{\ast}\mathbf{x}$. Note that because $\mathbf{A}$ may not be a square matrix, it would not have inverse in most cases. However, $\mathbf{A}^{\ast}$ could be viewed as a pseudo-inverse of $\mathbf{A}$. There exists some techniques where we could calculate $\mathbf{A}^{\ast}$ efficiently. And a research also discloses that such conclusion also holds when we consider a pseudo-inverse of a convolution.</p>
        <p>Considering that we have ground truth set $\mathbb{P}_r$, and the observation set $\mathbf{P}_y$. By $\mathbf{A}^{\ast}$ we could project the observation into a pseudo-inverse set $\mathbf{P}_n$. Then we could use such loss function to train network:</p>
        <div class="overflow">
        \begin{align}
            \mathcal{L} = \Psi_{\boldsymbol{\Theta}}(\mathbf{x}_r) - \Psi_{\boldsymbol{\Theta}}(\mathbf{x}_n) + \mu \max\left( \lVert \nabla_{\mathbf{x}_i} \Psi_{\boldsymbol{\Theta}}(\mathbf{x}_i) \rVert^2_2,~0\right)^2,
        \end{align}
        </div>
        <p>where $\mathbf{x}_r \sim \mathbb{P}_r$, $\mathbf{x}_n \sim \mathbb{P}_n$ and $\mathbf{x}_i = \varepsilon \mathbf{x}_r + (1 - \varepsilon \mathbf{x}_n)$. $\varepsilon$ is a random variable in the uniform distribution $U(0,~1)$. The last term in the loss function is used to enforce $\Psi_{\boldsymbol{\Theta}}$ to be Lipschitz continuous. During the training, we sample $\mathbf{x}_r$ and $\mathbf{x}_n$ randomly. Since they are not coupled, the loss function is essentially the Wasserstein distance which makes the network learn the minimal distance between the two distribution $\mathbb{P}_r$ and $\mathbb{P}_n$.</p>
        <p>After the network getting trained, the network parameter $\boldsymbol{\Theta}$ would be fixed. Then we could use gradient descent to solve the inverse problem:</p>
        <div class="overflow">
        \begin{align}
            \mathbf{x}^{k+1} = \mathbf{x}^k - \alpha \nabla_{\mathbf{x}} \left( \lVert \mathbf{y} - \mathbf{A}\mathbf{x}^k\rVert_2^2 + \lambda \Psi_{\boldsymbol{\Theta}}(\mathbf{x}^k) \right).
        \end{align}
        </div>
    </div>
  </div>
</div>

<h3 id="proximal-gradient-method">Proximal gradient method</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Parallel proximal methods for total variation minimization</li>
        <li><b>Author</b>: Ulugbek S. Kamilov</li>
        <li><b>Year</b>: 2017</li>
        <li><b>Theory level</b>: Theoretical</li>
        <li><b>Theory type</b>: Regularization</li>
        <li><b>Used data</b>: Shepp-Logan images</li>
        <li><b>Source</b>: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</li>
        </ul>
        <p style="text-indent:2em"><a href="https://ieeexplore.ieee.org/document/7472568" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>In this paper, the author gives the general formulation of the proximal algorithm where we need to solve that</p>
        <div class="overflow">
        \begin{align}
            \hat{\mathbf{x}} = \arg \min\limits_{\mathbf{x}} \mathcal{D}(\mathbf{x}) + \frac{1}{K} \sum_{k=1}^K \mathcal{R}_k(\mathbf{x}),
        \end{align}
        </div>
        <p>where $\mathcal{D},~\mathcal{R}_k$ are convex. Such problem often appears when solving dictionary learning. To get the solution, we need to apply ISTA-based optimization:</p>
        <div class="overflow">
        \begin{align}
            \mathbf{z}_t = \mathbf{x}_{t-1} - \gamma_t \nabla \mathcal{D} (\mathbf{x}_{t-1}), \\
            \mathbf{x}_t = \frac{1}{K} \sum_{k=1}^K \mathrm{prox}_{\gamma_t \mathcal{R}_k}(\mathbf{z}_t).
        \end{align}
        </div>
        <p>To learn the details about what is proximal operator ($\mathbf{prox}(\cdot)$) and how to solve it, please check:</p>
        <p style="text-indent:2em"><a href="../note20180813special/#proximal-gradient-method" class="button icon fa-file-text-o" style="text-indent:0em">Reference</a></p>
    </div>
  </div>
</div>

<h3 id="landweber-iteration">Landweber iteration</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Learning Model-Based Sparsity via Projected Gradient Descent</li>
        <li><b>Author</b>: Sohail Bahmani, Petros T. Boufounos, and Bhiksha Raj</li>
        <li><b>Year</b>: 2017</li>
        <li><b>Theory level</b>: Theoretical</li>
        <li><b>Theory type</b>: Regularization</li>
        <li><b>Used data</b>: None (pure theoretical)</li>
        <li><b>Source</b>: IEEE Transactions on Information Theory</li>
        </ul>
        <p style="text-indent:2em"><a href="https://ieeexplore.ieee.org/document/7373645" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>This paper gives the proof of how the Landweber iteration (Projected Gradient Descent) converges, and it also verify some other features like Stable Model-Restricted Hessian (SMRH) condition.</p>
        <p>The Landweber iteration is used when there is a strict constraint accompanied with the optimization.</p>
        <div class="overflow">
        \begin{align}
            \hat{\mathbf{x}} = \arg \min\limits_{\mathbf{x} \in \mathcal{C}} f(\mathbf{x}).
        \end{align}
        </div>
        <p>Different from the plain gradient descent, it needs to project the updated parameter to the strictly limited space:</p>
        <div class="overflow">
        \begin{align}
            \mathbf{x}_{t+1} = \mathcal{P}_{\mathcal{C}} (\mathbf{x}_t - \alpha \nabla f(\mathbf{x})).
        \end{align}
        </div>
        <p>Note that to solve this problem, we need to use the project function $\mathcal{P}$ which means we find a solution $\mathbf{x}_{t+1} \in \mathcal{C}$ that has the smallest distance to $\mathbf{x}_t - \alpha \nabla f(\mathbf{x})$.</p>
    </div>
  </div>
</div>

<h1 id="stochastic-methods">Stochastic methods</h1>

<h2 id="sampling-methods">Sampling methods</h2>

<h3 id="metropolis-hastings">Metropolis-Hastings</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Bayesian calibration of a large‐scale geothermal reservoir model by a new adaptive delayed acceptance Metropolis Hastings algorithm</li>
        <li><b>Author</b>: T. Cui, C. Fox, and M. J. O'Sullivan</li>
        <li><b>Year</b>: 2011</li>
        <li><b>Theory level</b>: Algorithm</li>
        <li><b>Theory type</b>: Stochastic sampling algorithm</li>
        <li><b>Used data</b>: Geothermal reservoir modeling</li>
        <li><b>Source</b>: Water Resources Research</li>
        </ul>
        <p style="text-indent:2em"><a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2010WR010352" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>Metropolis-Hastings method is widely used in Monte-Carlo-Markov-Chain (MCMC) methods. This paper proposes an improvement for solving inverse problems with a highly complicated forward model. Suppose we have a model function $\mathbf{f}$, the likelihood function derived from Bayesian method could be formulated as</p>
        <div class="overflow">
        \begin{align}
            p(\mathbf{x}|\mathbf{y}) \propto e^{-\frac{1}{2} (\mathbf{y} - \mathbf{f}(\mathbf{x}))^T \Sigma_e^{-1} (\mathbf{y} - \mathbf{f}(\mathbf{x})) } p(\mathbf{x}),
        \end{align}
        </div>
        <p>where $\Sigma_e$ is the covariance matrix of the misfit vector $\mathbf{e} = \mathbf{y} - \mathbf{f}(\mathbf{x})$. Note that if we have a coarse model $\mathbf{f}^{\ast}(\mathbf{x})$ which is derived by reducing the order of $\mathbf{f}$, then we would have $\mathbf{e} = \mathbf{y} - \mathbf{f}_d(\mathbf{x}) + \left(\mathbf{f}_d(\mathbf{x}) - \mathbf{f}(\mathbf{x}) \right)$. Denote that $\mathbf{d} = \mathbf{f}_d(\mathbf{x}) - \mathbf{f}(\mathbf{x})$, and suppose that $\mathbf{d} \sim \mathcal{N}(\mu_d, \Sigma_d)$. Then we would have a new likelihood function</p>
        <div class="overflow">
        \begin{align}
            p_d(\mathbf{x}|\mathbf{y}) \propto e^{-\frac{1}{2} (\mathbf{y}_d - \mathbf{f}_d(\mathbf{x}) - \mu_d )^T (\Sigma_e + \Sigma_d)^{-1} (\mathbf{y}_d - \mathbf{f}_d(\mathbf{x}) - \mu_d) } p(\mathbf{x}).
        \end{align}
        </div>
        <p>Suppose that we have a probability function $\mathbf{g}(\cdot)$, and random vector $\boldsymbol{\lambda}$ follows the distribution of $\mathbf{g}$. Then we could update a model parameter $\mathbf{x}_k$ by updating function $\mathbf{x}^{\dagger} = \boldsymbol{\eta}(\mathbf{x}_k,~\boldsymbol{\lambda})$. Consider another probablity function $\mathbf{g}_r(\cdots)$ which generates another random vector $\boldsymbol{\lambda}_r$. We may have another updating function $\mathbf{x}_k = \boldsymbol{\eta}_r(\mathbf{x}^{\dagger},~\boldsymbol{\lambda}_r)$. Hence we know $\boldsymbol{\eta},~\boldsymbol{\eta}_r$ are reverse transitions compared to each other. After that, we could define the proposal distribution as</p>
        <div class="overflow">
        \begin{equation}
          \left\{
          \begin{aligned}
            &q(\mathbf{x}_k \rightarrow \mathbf{x}^{\dagger}) = g(\boldsymbol{\lambda}),\\
            &q(\mathbf{x}^{\dagger} \rightarrow \mathbf{x}_k) = g_r(\boldsymbol{\lambda}_r) \mathbf{J}, \\
            &\mathbf{J} = \left| \frac{ \partial \boldsymbol{\eta} \left( \begin{bmatrix} \mathbf{x} \\ \boldsymbol{\lambda} \end{bmatrix} \right) }{ \partial \begin{bmatrix} \mathbf{x} \\ \boldsymbol{\lambda} \end{bmatrix} } \right|.
          \end{aligned}
          \right.
        \end{equation}
        </div>
        <p>Then, the Metropolis-Hastings algorithm could be described as</p>
        <ol>
          <li>Generate a random update $\mathbf{x}^{\dagger}$ and calculate its bi-directional transitions $q(\mathbf{x}_k \rightarrow \mathbf{x}^{\dagger}) ,~ q(\mathbf{x}^{\dagger} \rightarrow \mathbf{x}_k)$.</li>
          <li>Use Metropolis-Hastings algorithm to calculate acception rate over the coarse likelihood:
            <div class="overflow">
            \begin{align}
                \alpha(\mathbf{x}_k ,~ \mathbf{x}^{\dagger}) = \min \left( 1,~ \frac{p_d(\mathbf{x}^{\dagger}|\mathbf{y}) q(\mathbf{x}^{\dagger} \rightarrow \mathbf{x}_k)}{p_d(\mathbf{x}_k|\mathbf{y}) q(\mathbf{x}_k \rightarrow \mathbf{x}^{\dagger})} \right).
            \end{align}
            </div>
          </li>
          <li>If $\mathbf{x}^{\dagger}$ could be accept according to the acception rate $\alpha$, then calculate another accpetion rate over the detail likelihood:
            <div class="overflow">
            \begin{align}
                \beta(\mathbf{x}_k ,~ \mathbf{x}^{\dagger}) = \min \left( 1,~ \frac{p(\mathbf{x}^{\dagger}|\mathbf{y}) \alpha(\mathbf{x}^{\dagger} ,~ \mathbf{x}_k) q(\mathbf{x}^{\dagger} \rightarrow \mathbf{x}_k)}{p(\mathbf{x}_k|\mathbf{y}) \alpha(\mathbf{x}_k ,~ \mathbf{x}^{\dagger}) q(\mathbf{x}_k \rightarrow \mathbf{x}^{\dagger})} \right).
            \end{align}
            </div>
          </li>
          <li>If $\mathbf{x}^{\dagger}$ could be accept according to the acception rate $\beta$, then perform update $\mathbf{x}_{k+1} = \mathbf{x}^{\dagger}$.</li>
        </ol>
        <p>The idea of this algorithm is, if the sample is rejected by the coarse likelihood, then we do not need to calculate the complicated forward model. Although calculating the coarse model would reduce the efficiency, if the sample is easy to be rejected, then we would gain better performance by this method.</p>
    </div>
  </div>
</div>

<h3 id="gibbs-sampling">Gibbs sampling</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: A Bayesian inference approach to the inverse heat conduction problem</li>
        <li><b>Author</b>: Jingbo Wang, and Nicholas Zabaras</li>
        <li><b>Year</b>: 2004</li>
        <li><b>Theory level</b>: Algorithm</li>
        <li><b>Theory type</b>: Stochastic sampling algorithm</li>
        <li><b>Used data</b>: Two-dimensional inverse heat conduction problem (IHCP)</li>
        <li><b>Source</b>: International Journal of Heat and Mass Transfer</li>
        </ul>
        <p style="text-indent:2em"><a href="https://www.sciencedirect.com/science/article/pii/S0017931004000985" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
        <ul>
          <li><b>External Reference</b>: This is another article about solving multi-frequency problem (i.e. multiple forward model) with Gibbs sampling:</li>
        </ul>
        <p style="text-indent:2em"><a href="https://asa.scitation.org/doi/10.1121/1.1419086" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>In this paper, we have $y_j \sim \mathbf{T}(\mathbf{x},t_j)$, and $k \frac{\partial T(\mathbf{x}, t)}{\partial \mathbf{n}} = \sum \theta_i \mathbf{w}_i (\mathbf{x},~t)$. Hence we define that vector $\mathbf{y}$ should fulfil that $\mathbf{y} \sim \mathbf{f} (\boldsymbol{\theta})$, where $\mathbf{f}(\cdot)$ is known by some prior work.</p>
        <p>According to Bayesian method, $p(\boldsymbol{\theta}|\mathbf{y}) \propto p(\mathbf{y}|\boldsymbol{\theta}) p(\boldsymbol{\theta})$, hence we have</p>
        <div class="overflow">
        \begin{align}
            p(\boldsymbol{\theta}|\mathbf{y}) \propto e^{-\frac{1}{2\sigma^2}\left( \mathbf{f}(\boldsymbol{\theta}) - \mathbf{y} \right)^T\left( \mathbf{f}(\boldsymbol{\theta}) - \mathbf{y} \right)} p(\boldsymbol{\theta}).
        \end{align}
        </div>
        <p>To specify the prior $p(\boldsymbol{\theta})$, we use the random field, which means</p>
        <div class="overflow">
        \begin{align}
            p(\boldsymbol{\theta}) \propto e^{-\sum_{i,~j} W_{ij} (\theta_i - \theta_j)^2} = \lambda^{\frac{m}{2}} e^{- \frac{1}{2} \boldsymbol{\theta}^T \mathbf{W} \boldsymbol{\theta}}
        \end{align}
        </div>
        <p>Then in each iteration, we could use Gibbs sampling method, which means in the k<sup>th</sup> iteration, if we have $\boldsymbol{\theta}^{(k)}$, then we perform that</p>
        <div class="overflow">
        <ol>
          <li>$\theta^{(k+1)}_1 \sim p\left(\theta_1 \left| \theta_2=\theta^{(k)}_2,~ \theta_3=\theta^{(k)}_3,~ \theta_n=\theta^{(k)}_n \right.\right)$</li>
          <li>$\theta^{(k+1)}_2 \sim p\left(\theta_2 \left| \theta_1=\theta^{(k+1)}_1,~ \theta_3=\theta^{(k)}_3,~ \theta_n=\theta^{(k)}_n \right.\right)$</li>
          <li>$\theta^{(k+1)}_3 \sim p\left(\theta_3 \left| \theta_1=\theta^{(k+1)}_2,~ \theta_2=\theta^{(k+1)}_2,~ \theta_n=\theta^{(k)}_n \right.\right)$</li>
          <li>...</li>
          <li>$\theta^{(k+1)}_n \sim p\left(\theta_n \left| \theta_1=\theta^{(k+1)}_1,~ \theta_2=\theta^{(k+1)}_2,~ \theta_n=\theta^{(k+1)}_{n-1} \right.\right)$</li>
        </ol>
        </div>
    </div>
  </div>
</div>

<h2 id="heuristic-methods">Heuristic methods</h2>

<h3 id="ant-colony-algorithm">Ant colony algorithm</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: Application of homogenous continuous Ant Colony Optimization algorithm to inverse problem of one-dimensional coupled radiation and conduction heat transfer</li>
        <li><b>Author</b>: Biao Zhang, Hong Qi, Ya-Tao Ren, Shuang-Cheng Sun, and Li-Ming Ruan</li>
        <li><b>Year</b>: 2013</li>
        <li><b>Theory level</b>: Algorithm</li>
        <li><b>Theory type</b>: Stochastic heruistic algorithm</li>
        <li><b>Used data</b>: Steady-state coupled radiation and conduction heat transfer in an absorbing, emitting and scattering
plane-parallel slab</li>
        <li><b>Source</b>: International Journal of Heat and Mass Transfer</li>
        </ul>
        <p style="text-indent:2em"><a href="https://www.sciencedirect.com/science/article/pii/S001793101300608X" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
        <ul>
          <li><b>External Reference</b>: To learn a visual demo for ant colony optimization, please check this link:</li>
        </ul>
        <p style="text-indent:2em"><a href="http://lab.breezedust.com/aco/" class="button icon fa-area-chart" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>This paper introduce a method where we could enhance the optimization results by ant colony optimization (ACO). First, this paper introduce the basic-ACO (BACO), which shrinks the search scope in each iteration to reduce the calculation complexity. However, because of the grid-scheme and the scope-shrinking strategy, BACO may converge to the local minimum in some cases. To solve this problem, in this paper the author proposes the homogeneous ACO (HACO).</p>
        <p>Suppose that we need to solve $\arg \min\limits_{\mathbf{x}} \lVert \mathbf{y} - \mathbf{f}(\mathbf{x})\rVert_2^2$, where $\mathbf{f}$ is a highly nonlinear model. Then we could initialize $M$ solutions $\mathbf{x}^{(1)},\mathbf{x}^{(2)},\cdots,\mathbf{x}^{(M)}$, which is also called "ants" in ACO. Suppose that the metric function $\mathcal{L}(\mathbf{x})=\frac{1}{N}\left\lVert \mathbf{y} - \mathbf{f}\left(\mathbf{x}^{(k)}\right) \right\rVert_2$ is used to evaluate the solution $\mathbf{x}^{(k)}$. For each parameter of any $\mathbf{x}^{(k)}=\begin{bmatrix}x^{(k)}_1 & x^{(k)}_2 & \cdots & x^{(1)}_n \end{bmatrix}$, we set the initial searching scope $x^{(k)}_i \in [L_i, S_i]$ and divide the scope into $N_i$ intervals. Then we could get a series of discrete positions. Initialize that $\tau_{ij} = Q$ and $\eta_{ij} = \frac{1}{N}$. After that we could perform such iterations:</p>
        <div class="overflow">
        <ol>
          <li>For each solution $k$, $p^{(k)}_{ij} = \frac{\zeta}{N_i} + \left( 1 - \zeta \right)\frac{ \tau^{\alpha}_{ij} \eta^{\beta}_{ij} }{ \sum_{j=1}^{N_i} \tau^{\alpha}_{ij} \eta^{\beta}_{ij} }$, where $\alpha,~\beta &gt; 0$ and $\zeta \in [0,~1]$. $p^{(k)}_{ij}$ is the probability that how possible $x^{(k)}_i$ would transfer into $x^{(k)}_j$. Since when $\zeta \rightarrow 1$, the move tends to be random, we call such update "homogeneous updating".</li>
          <li>After we update the new solutions according to $p^{(k)}_{ij}$, we could search a local minimum for each solution in a local area. This search could be totally random, i.e. we just adjust the solutions by adding random noise. And we could also use some deterministic methods. If we calculate $\mathcal{L}(\mathbf{x}^{(k)})$ for each solution, the local minimum should satisfy that $\mathcal{L}(\mathbf{x}^{(k)} + \boldsymbol{\varepsilon}^{(k)}) &lt; \mathcal{L}(\mathbf{x}^{(k)})$. This step is designed for reducing the discrete sampling effect. Record and update the historical best solution $\mathbf{x}^{\ast}$ and the best 3 solutions in this step: $\mathbf{x}^{(s_1)},~\mathbf{x}^{(s_2)},~\mathbf{x}^{(s_3)}$.</li>
          <li>Calculate the increments for each solution $k$, which means in step 1, if $x^{(k)}_i$ changes to $x^{(k)}_j$, then we have $\Delta \tau^{(k)}_{ij} = Q$ and $\Delta \eta^{(k)}_{ij} = \frac{1}{N \mathcal{L}(\mathbf{x}_j)}$.</li>
          <li>Update the information variables: 
          \begin{align*}
            \tau_{ij} &= (1-\rho) \tau_{ij} + \sum_{k=1}^{M} \Delta \tau^{(k)}_{ij},\\
            \eta_{ij} &= \max \left( \eta_{ij},~ \sum_{k=1}^{M} \Delta \eta^{(k)}_{ij} \right).
          \end{align*}
          </li>
          <li>Defining $\gamma \in (0,1)$ which indicates the shrinking ratio. Then we could shrink the searching scopes according to such equations:
          \begin{align*}
            L_i &= \max \left( \min \left( x^{\ast}_i,~ x^{(s_1)}_i,~ x^{(s_2)}_i,~ x^{(s_3)}_i \right) - \gamma \frac{S_i - L_i}{2},~ L_i \right),\\
            S_i &= \min \left( \max \left( x^{\ast}_i,~ x^{(s_1)}_i,~ x^{(s_2)}_i,~ x^{(s_3)}_i \right) + \gamma \frac{S_i - L_i}{2},~ S_i \right).
          \end{align*}
          </li>
          <li>Resampling the new $N_i$ intervals according to new scope $x^{(k)}_i \in [L_i, S_i]$. Note that we need to interpolate $\tau_{ij},~\eta_{ij}$ for new intervals due to the resampling. Then start a new loop beginning from step 1.</li>
        </ol>
        </div>
    </div>
  </div>
</div>

<h3 id="bat-algorithm">Bat algorithm</h3>

<div class='box' style="margin-left:2em">
  <div class='row' style="margin-left:0em">
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <ul>
        <li><b>Title</b>: A New Metaheuristic Bat-Inspired Algorithm</li>
        <li><b>Author</b>: Xin-She Yang</li>
        <li><b>Year</b>: 2010</li>
        <li><b>Theory level</b>: Algorithm</li>
        <li><b>Theory type</b>: Stochastic heruistic algorithm</li>
        <li><b>Used data</b>: Standard benchmark non-linear functions</li>
        <li><b>Source</b>: Nature Inspired Cooperative Strategies for Optimization</li>
        </ul>
        <p style="text-indent:2em"><a href="https://arxiv.org/abs/1004.4170" class="button icon fa-file-pdf-o" style="text-indent:0em">Reference</a></p>
    </div>
    <div class="6u 12u(mobilep)" style="margin-bottom:2em">
        <h4 class="cancel_link">Learning abstract:</h4>
        <p>Bat algorithm could be viewed as an adaptation of particle swarm optimizaion (PSO). The author of this paper has proposed several algorithms in this kind, for example, the firefly algorithm. This algorithm imitates bats' behavior. When they have not hunt the best solution, they tend to move close to the current optimal solution; once they get the best solution, they would try to stay in the local position.</p>
        <p>Consider we have the loss function $\mathcal{L}(\mathbf{x})$, and we initialize a series of solutions randomly $\mathbf{x}_1,~\mathbf{x}_2,~\mathbf{x}_n$, where each solution could be viewed as a bat. Attach each bat with a velocity $\mathbf{v}_i$, a frequency $f_i$, a pulse rate $r_i=0$, and a loudness $A_i=1$. Set $\alpha &lt; 1$. Then perform such iterations:</p>
        <div class="overflow">
        <ol>
          <li>In iteration $t$, mark the current optimal solution as $\mathbf{x}^{\ast}$. For each bat (solution) $\mathbf{x}_i$, generate a new solution $\mathbf{x}'_i$:
            <ol>
              <li>Update its frequency in uniform distribution $f_i \sim U(0,~\alpha)$.</li>
              <li>Update the velocity $\mathbf{v}'_{i} = \mathbf{v}_{i} (1-f_i) + \left( \mathbf{x}^{\ast} - \mathbf{x}_i\right) f_i$.</li>
              <li>Update its position $\mathbf{x}'_i = \mathbf{x}_i + \mathbf{v}'_{i}$.</li>
              <li>Generate $r \sim U(0,1)$. If $r &gt; r_i$, select a solution from the M best solutions. And use a random vector $\boldsymbol{\epsilon}$ to update it, i.e. $\mathbf{x}'_i = \mathbf{x}_{\mathrm{selected}} + \mathrm{diag}(\boldsymbol{\epsilon})\mathbf{A}$.</li>
              <li>Adjust $\mathbf{x}_i$ slightly and randomly.</li>
              <li>Generate $a \sim U(0,1)$. If $a &lt; A_i$, and $\mathcal{L}(\mathbf{x}'_i) < \mathcal{L}(\mathbf{x}_i)$, then let
              \begin{align*}
                \mathbf{x}_i &= \mathbf{x}'_i,\\
                r_i &= 1 - e^{\lambda t},\\
                A_i &= \beta A_i.
              \end{align*}
              </li>
            </ol>
          </li>
          <li>After iteration $t$, sort all solutions $\{\mathbf{x}_i\}$, then we could update the optimal solution $\mathbf{x}^{\ast}$.</li>
        </ol>
        </div>
        <p>In the beginning, $r$ is small while $A$ is large, the algorithm tends to abandon the solutions which are not good and accept new solutions. When the algorithm is nearly converged, the new solutions would not be accepted.</p>
    </div>
  </div>
</div>

<h1 id="related-slides">Related slides</h1>

<h2 id="slides-on-week-1-feb-1-2019">Slides on week 1, Feb. 1, 2019</h2>

<div class="youtube container">
    <object class="docs" data="https://cainmagi.github.io/notes/note20190129/yjin4-week1-02012019.pdf" type="application/pdf">
        <div class="box center">
            <p style="top:10%;color:#FCC; margin-bottom:0.2em"><i class="fa fa-exclamation-triangle" aria-hidden="true"></i> Ooops! Your browser does not support viewing pdfs.</p> 
            <p style="top:50%;text-align:center;height:100%; display:block"><a href="https://cainmagi.github.io/notes/note20190129/yjin4-week1-02012019.pdf" class="button icon fa-pdf-o">Download PDF</a></p>
        </div>
    </object>
</div>

<h2 id="slides-on-week-2-feb-8-2019">Slides on week 2, Feb. 8, 2019</h2>

<div class="youtube container">
    <object class="docs" data="https://cainmagi.github.io/notes/note20190129/yjin4-week2-02082019.pdf" type="application/pdf">
        <div class="box center">
            <p style="top:10%;color:#FCC; margin-bottom:0.2em"><i class="fa fa-exclamation-triangle" aria-hidden="true"></i> Ooops! Your browser does not support viewing pdfs.</p> 
            <p style="top:50%;text-align:center;height:100%; display:block"><a href="https://cainmagi.github.io/notes/note20190129/yjin4-week2-02082019.pdf" class="button icon fa-pdf-o">Download PDF</a></p>
        </div>
    </object>
</div>

<h2 id="slides-on-week-3-a-feb-13-2019">Slides on week 3-a, Feb. 13, 2019</h2>

<div class="youtube container">
    <object class="docs" data="https://cainmagi.github.io/notes/note20190129/yjin4-week3a-02132019.pdf" type="application/pdf">
        <div class="box center">
            <p style="top:10%;color:#FCC; margin-bottom:0.2em"><i class="fa fa-exclamation-triangle" aria-hidden="true"></i> Ooops! Your browser does not support viewing pdfs.</p> 
            <p style="top:50%;text-align:center;height:100%; display:block"><a href="https://cainmagi.github.io/notes/note20190129/yjin4-week3a-02132019.pdf" class="button icon fa-pdf-o">Download PDF</a></p>
        </div>
    </object>
</div>

<h2 id="slides-on-week-3-b-feb-15-2019">Slides on week 3-b, Feb. 15, 2019</h2>

<div class="youtube container">
    <object class="docs" data="https://cainmagi.github.io/notes/note20190129/yjin4-week3b-02152019.pdf" type="application/pdf">
        <div class="box center">
            <p style="top:10%;color:#FCC; margin-bottom:0.2em"><i class="fa fa-exclamation-triangle" aria-hidden="true"></i> Ooops! Your browser does not support viewing pdfs.</p> 
            <p style="top:50%;text-align:center;height:100%; display:block"><a href="https://cainmagi.github.io/notes/note20190129/yjin4-week3b-02152019.pdf" class="button icon fa-pdf-o">Download PDF</a></p>
        </div>
    </object>
</div>

                        </div>
                    </section>
            <!-- Disqus Inject -->
                
                  <section>
    <div class="inner" id="disqus_thread"></div>
    <script type="text/javascript">

    (function() {
          
          
          if (window.location.hostname == "localhost")
                return;

          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          var disqus_shortname = 'rosenkreutz-studio';
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <div class="inner"><a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a></div>
</section>
                
            </div>
            
        <!-- Footer -->
            
                <!-- Footer -->
    <footer id="footer">
        <div class="inner">
            <ul class="icons">
                
                    <li><a href="mailto:cainmagi@gmail.com" class="icon alt fa-envelope" target="_blank"><span class="label">Email</span></a></li>
                
                    <li><a href="https://weibo.com/u/5885093621" class="icon alt fa-weibo" target="_blank"><span class="label">Weibo</span></a></li>
                
                    <li><a href="https://github.com/cainmagi" class="icon alt fa-github" target="_blank"><span class="label">GitHub</span></a></li>
                
                    <li><a href="https://steamcommunity.com/id/cainmagi" class="icon alt fa-steam" target="_blank"><span class="label">Steam</span></a></li>
                
                    <li><a href="https://www.youtube.com/channel/UCzqpNK5qFMy5_cI1i0Z1nQw" class="icon alt fa-youtube-play" target="_blank"><span class="label">Youtube</span></a></li>
                
                    <li><a href="https://music.163.com/#/user/home?id=276304206" class="icon alt fa-music" target="_blank"><span class="label">Netease Music</span></a></li>
                
            </ul>
            <ul class="copyright">
                <li>&copy; Well-logging laboratory, Department of Electrical and Computer Engineering, University of Houston</li>
                
            </ul>
        </div>
    </footer>

            
        </div>

    <!-- Scripts -->
        <!-- Scripts -->
    <!-- jQuery -->
    <script src="https://cainmagi.github.io/js/jquery.min.js"></script>
    <script src="https://cainmagi.github.io/js/jquery.scrolly.min.js"></script>
    <script src="https://cainmagi.github.io/js/jquery.scrollex.min.js"></script>
    <script src="https://cainmagi.github.io/js/jquery.elevatezoom.js" type="text/javascript"></script>
    <script src="https://cainmagi.github.io/js/jquery.images.js"></script>
    <script src="https://cainmagi.github.io/js/skel.min.js"></script>
    <script src="https://cainmagi.github.io/js/util.js"></script>
    <script type="text/javascript" src="https://cainmagi.github.io/js/tooltipster.bundle.min.js"></script>

    

    <!-- Main JS -->
    <script src="https://cainmagi.github.io/js/main.js"></script>
    <script src="https://cainmagi.github.io/js/extensions.js"></script>
    
    
    <script src="https://cainmagi.github.io/js/title.js"></script>
    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-119875813-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
    
    <script src="https://cainmagi.github.io/js/highlight.pack.js"></script>
    <link rel="stylesheet" href="https://cainmagi.github.io/css/vs2015adp.css">
    <script>hljs.initHighlightingOnLoad();</script>
    
    <script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
          extensions: ["AMSmath.js", "AMSsymbols.js", "boldsymbol.js", "color.js"]
      }
    }
  });

  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
    
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

    

    

    </body>
</html>
