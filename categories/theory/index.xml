<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Theory on Rosenkreutz Studio</title>
    <link>https://cainmagi.github.io/categories/theory/</link>
    <description>Recent content in Theory on Rosenkreutz Studio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Aug 2019 02:02:02 -0500</lastBuildDate>
    
	<atom:link href="https://cainmagi.github.io/categories/theory/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Chinese translated lecture notes for MATH 6366 @ UH</title>
      <link>https://cainmagi.github.io/notes/note20190820special/</link>
      <pubDate>Tue, 20 Aug 2019 02:02:02 -0500</pubDate>
      
      <guid>https://cainmagi.github.io/notes/note20190820special/</guid>
      <description> 
这个项目还在施工中！如果你发现本译丛有任何问题，欢迎在下方的讨论版指正，译者不胜感激。
 </description>
    </item>
    
    <item>
      <title>Special Notes on May 15, 2019</title>
      <link>https://cainmagi.github.io/notes/note20190515special/</link>
      <pubDate>Wed, 15 May 2019 17:40:04 -0500</pubDate>
      
      <guid>https://cainmagi.github.io/notes/note20190515special/</guid>
      <description>In this article, we would discuss the trick about training and testing phases for dictionary learning (sparse coding). The original work could be referred here. As extra reading materials, we suggest reading Convex Optimization for understanding how to apply Lagrangian method and Matrix Cookbook to refer some conclusions about how to calculate gradients for matrices.
The pdf version of this article could be found here:
PDF version
Solve the Lasso problem Consider the testing phase of sparse coding which could be formulated as</description>
    </item>
    
    <item>
      <title>Notes on May 05, 2019</title>
      <link>https://cainmagi.github.io/notes/note20190505/</link>
      <pubDate>Sun, 05 May 2019 12:06:02 -0500</pubDate>
      
      <guid>https://cainmagi.github.io/notes/note20190505/</guid>
      <description>Introduction In this article, we would introduce two SEG-2018 expanded abstracts. The first one is about a new learning algorithm for transient electromagnetic method (TEM) inversion, and the second one is about using deep learning to solve FWI. In the following parts, we would discuss about the problems of the two papers and analyze which parts are not well proved. The two papers are listed below.
[1]: Application of supervised descent method for transient EM data inversion:</description>
    </item>
    
    <item>
      <title>Special Notes on Feb. 28, 2019</title>
      <link>https://cainmagi.github.io/notes/note20190228special/</link>
      <pubDate>Thu, 28 Feb 2019 02:04:28 -0600</pubDate>
      
      <guid>https://cainmagi.github.io/notes/note20190228special/</guid>
      <description>Introduction In this article, we would discuss the non-negative constrained least length problem. Due to the limitation of time, we only discuss the simplified form of this problem. The solution of this problem is derived from applying non-negative least squares algorithm.
KT conditions Check here to see Karush–Kuhn–Tucker conditions in Wikipedia.
 To solve this problem, first we need to introduce the Kuhn-Tucker (KT) theorem (or KT conditons).</description>
    </item>
    
    <item>
      <title>Notes on Feb. 23, 2019</title>
      <link>https://cainmagi.github.io/notes/note20190223/</link>
      <pubDate>Sat, 23 Feb 2019 07:49:01 -0600</pubDate>
      
      <guid>https://cainmagi.github.io/notes/note20190223/</guid>
      <description> Notes During this week, here is no note. A detail version about the works in this week has been updated in
Reference
Slides View the slides here:
 Ooops! Your browser does not support viewing pdfs.
Download PDF
  Ooops! Your browser does not support viewing pdfs.
Download PDF
 </description>
    </item>
    
    <item>
      <title>Stochastic optimization I: from Monte-Carlo methods to Gibbs sampling</title>
      <link>https://cainmagi.github.io/notes/note20190215special/</link>
      <pubDate>Fri, 15 Feb 2019 13:04:50 -0600</pubDate>
      
      <guid>https://cainmagi.github.io/notes/note20190215special/</guid>
      <description>Introduction This is a series of inspection on stochastic methods. Traditionally, an optimization problem could be solved by gradient descent methods, greedy algorithm and stochastic methods. For example, Levenberg–Marquardt algorithm is a gradient descent based methods. Another example is OMP which is used to find a local minimum of L0 penalized problem. Since the L0 norm is totally indifferentiable, we could not calculate its gradient. Therefore, such kind of problem is generally more difficult than those differentiable problems.</description>
    </item>
    
    <item>
      <title>Special Notes on Aug. 24, 2018</title>
      <link>https://cainmagi.github.io/notes/note20180824special/</link>
      <pubDate>Fri, 24 Aug 2018 03:45:41 -0500</pubDate>
      
      <guid>https://cainmagi.github.io/notes/note20180824special/</guid>
      <description>Introduction Check here to see Levenberg–Marquardt algorithm in Wikipedia.
 Check this link and we could review the theory of Levenberg–Marquardt algorithm (LMA), which is used as an improvement compared to the plain first-order gradient descent method. In this short discussion, we would like to talk about how and why we could derive such a method. Then we would know that when we could use this method and when we could not.</description>
    </item>
    
  </channel>
</rss>